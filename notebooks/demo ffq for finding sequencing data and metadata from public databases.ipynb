{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "560ae4ab-316f-46a8-bbe0-7ef8aa17c601",
   "metadata": {},
   "source": [
    "# demo ffq for finding sequencing data and metadata from public databases\n",
    "\n",
    ">\"[`ffq` (Fetch FastQ)](https://github.com/pachterlab/ffq) is a command line tool for finding sequencing data from public databases. \"ffq receives an accession and returns the metadata for that accession as well as the metadata for all downstream accessions following the connections between GEO, SRA, EMBL-EBI, DDBJ, and Biosample\" - SOURCE: https://github.com/pachterlab/ffq\n",
    "\n",
    "This notebook demonstrates a number of ways to use ffq. Including options for where you may have a hard time using it on the command line because on a remote machine where it doesn't install the same as locally, or at least make it easy to use the command line.\n",
    "\n",
    "Note if you are interested in metadata, you may want to check out Logan Search as it exposes a lot of detail, more than I see ffq access with an accession (although there may ways I haven't explored for ffq). Anyway, see [my logan_results_analysis-binder](https://github.com/fomightez/logan_results_analysis-binder/) for more information about Logan Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587a9039-308e-498b-accc-62ea6db166b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ffq -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07e6b79-656d-463c-841a-d9a1c14bee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ffq [-h] [-o OUT] [-l LEVEL] [--ftp] [--aws] [--gcp] [--ncbi] [--split]\n",
      "           [--verbose] [--version]\n",
      "           IDs [IDs ...]\n",
      "\n",
      "ffq 0.3.1: A command line tool to find sequencing data from SRA / GEO / ENCODE\n",
      "/ ENA / EBI-EMBL / DDBJ / Biosample.\n",
      "\n",
      "positional arguments:\n",
      "  IDs         One or multiple SRA / GEO / ENCODE / ENA / EBI-EMBL / DDBJ /\n",
      "              Biosample accessions, DOIs, or paper titles\n",
      "\n",
      "options:\n",
      "  -h, --help  Show this help message and exit\n",
      "  -o OUT      Path to write metadata (default: standard out)\n",
      "  -l LEVEL    Max depth to fetch data within accession tree\n",
      "  --ftp       Return FTP links\n",
      "  --aws       Return AWS links\n",
      "  --gcp       Return GCP links\n",
      "  --ncbi      Return NCBI links\n",
      "  --split     Split output into separate files by accession (`-o` is a\n",
      "              directory)\n",
      "  --verbose   Print debugging information\n",
      "  --version   show program's version number and exit\n"
     ]
    }
   ],
   "source": [
    "!ffq --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b31e92-5257-434f-bc9a-fa4c6c302216",
   "metadata": {},
   "source": [
    "Of course, that's how you use it inside a running Jupyter Notebook.  \n",
    "**If you were on the command line, you'd leave off the exclamation point**. Otherwise,the same commands shown in this section would be used in the same manner and yield the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "504c36d0-b207-41fb-9360-e013a920a22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:16,196]    INFO Parsing run ERR5670887\n",
      "{\n",
      "    \"ERR5670887\": {\n",
      "        \"accession\": \"ERR5670887\",\n",
      "        \"experiment\": \"ERX5386380\",\n",
      "        \"study\": \"ERP125915\",\n",
      "        \"sample\": \"ERS6200127\",\n",
      "        \"title\": \"MinION sequencing\",\n",
      "        \"attributes\": {\n",
      "            \"ENA-FIRST-PUBLIC\": \"2021-07-01\",\n",
      "            \"ENA-LAST-UPDATE\": \"2021-07-01\"\n",
      "        },\n",
      "        \"files\": {\n",
      "            \"ftp\": [],\n",
      "            \"aws\": [],\n",
      "            \"gcp\": [],\n",
      "            \"ncbi\": []\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ffq ERR5670887\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf50ce9-d0d8-4179-990c-26d186484c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:18,012]    INFO Parsing run ERR5654687\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "!ffq --ncbi ERR5654687\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3969e-b742-4dee-a41a-9d610cf6476a",
   "metadata": {},
   "source": [
    "I found I get more associated metadata using the 'sample' listed in the ffq results for an SRA entry. (Not the same as the 'BioSample' that begins usually with `SAMN`.) Here is executing `ffq` with the one listed from the results of `!ffq ERR5670887` earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91e62d84-b3eb-4993-b3f5-ab98aec51471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:19,610]    INFO Parsing sample ERS6200127\n",
      "[2025-04-16 19:58:19,771] WARNING Failed to parse sample information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:19,920]    INFO Getting Experiment for ERS6200127\n",
      "[2025-04-16 19:58:19,920]    INFO Parsing Experiment ERX5386380\n",
      "[2025-04-16 19:58:20,074] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:20,201] WARNING There is 1 run for ERX5386380\n",
      "[2025-04-16 19:58:20,202]    INFO Parsing run ERR5670887\n",
      "{\n",
      "    \"ERS6200127\": {\n",
      "        \"accession\": \"ERS6200127\",\n",
      "        \"title\": \"OC43-MRC5-STM2120\",\n",
      "        \"organism\": \"Homo sapiens\",\n",
      "        \"attributes\": {\n",
      "            \"ENA-CHECKLIST\": \"ERC000011\",\n",
      "            \"ENA-FIRST-PUBLIC\": \"2021-07-01\",\n",
      "            \"organism\": \"Homo sapiens\",\n",
      "            \"ENA-LAST-UPDATE\": \"2021-07-01\",\n",
      "            \"scientific_name\": \"Homo sapiens\",\n",
      "            \"common name\": \"human\",\n",
      "            \"cell_type\": \"MRC5\"\n",
      "        },\n",
      "        \"experiments\": {\n",
      "            \"ERX5386380\": {\n",
      "                \"accession\": \"ERX5386380\",\n",
      "                \"title\": \"MinION sequencing\",\n",
      "                \"platform\": \"OXFORD_NANOPORE\",\n",
      "                \"instrument\": \"MinION\",\n",
      "                \"runs\": {\n",
      "                    \"ERR5670887\": {\n",
      "                        \"accession\": \"ERR5670887\",\n",
      "                        \"experiment\": \"ERX5386380\",\n",
      "                        \"study\": \"ERP125915\",\n",
      "                        \"sample\": \"ERS6200127\",\n",
      "                        \"title\": \"MinION sequencing\",\n",
      "                        \"attributes\": {\n",
      "                            \"ENA-FIRST-PUBLIC\": \"2021-07-01\",\n",
      "                            \"ENA-LAST-UPDATE\": \"2021-07-01\"\n",
      "                        },\n",
      "                        \"files\": {\n",
      "                            \"ftp\": [],\n",
      "                            \"aws\": [],\n",
      "                            \"gcp\": [],\n",
      "                            \"ncbi\": []\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ffq ERS6200127"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161d05cd-5883-4173-af3c-8ea0378f0fe8",
   "metadata": {},
   "source": [
    "And for a different one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3111f72-71bc-43d5-9d5e-3ca3079db9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:21,822]    INFO Parsing sample SRS3243030\n",
      "[2025-04-16 19:58:22,136] WARNING Failed to parse sample information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:22,329]    INFO Getting Experiment for SRS3243030\n",
      "[2025-04-16 19:58:22,329]    INFO Parsing Experiment SRX4022539\n",
      "[2025-04-16 19:58:22,506] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:22,642] WARNING There is 1 run for SRX4022539\n",
      "[2025-04-16 19:58:22,642]    INFO Parsing run SRR7093892\n",
      "{\n",
      "    \"SRS3243030\": {\n",
      "        \"accession\": \"SRS3243030\",\n",
      "        \"title\": \"98_17yr_Male_Caucasian\",\n",
      "        \"organism\": \"Homo sapiens\",\n",
      "        \"attributes\": {\n",
      "            \"INSDC secondary accession\": \"SRS3243030\",\n",
      "            \"NCBI submission package\": \"Generic.1.0\",\n",
      "            \"disease\": \"Normal\",\n",
      "            \"ethnicity\": \"Caucasian\",\n",
      "            \"organism\": \"Homo sapiens\",\n",
      "            \"Sex\": \"male\",\n",
      "            \"cell id\": \"GM07753\",\n",
      "            \"age\": \"17\",\n",
      "            \"source_name\": \"Skin; Unspecified\",\n",
      "            \"BioSampleModel\": \"Generic\",\n",
      "            \"ENA-FIRST-PUBLIC\": \"2022-03-29\",\n",
      "            \"ENA-LAST-UPDATE\": \"2022-03-29\"\n",
      "        },\n",
      "        \"experiments\": {\n",
      "            \"SRX4022539\": {\n",
      "                \"accession\": \"SRX4022539\",\n",
      "                \"title\": \"GSM3124643: 98_17yr_Male_Caucasian; Homo sapiens; RNA-Seq\",\n",
      "                \"platform\": \"ILLUMINA\",\n",
      "                \"instrument\": \"NextSeq 500\",\n",
      "                \"runs\": {\n",
      "                    \"SRR7093892\": {\n",
      "                        \"accession\": \"SRR7093892\",\n",
      "                        \"experiment\": \"SRX4022539\",\n",
      "                        \"study\": \"SRP144355\",\n",
      "                        \"sample\": \"SRS3243030\",\n",
      "                        \"title\": \"NextSeq 500 sequencing; GSM3124643: 98_17yr_Male_Caucasian; Homo sapiens; RNA-Seq\",\n",
      "                        \"attributes\": {\n",
      "                            \"ENA-FIRST-PUBLIC\": \"2018-11-18\",\n",
      "                            \"ENA-LAST-UPDATE\": \"2018-11-18\"\n",
      "                        },\n",
      "                        \"files\": {\n",
      "                            \"ftp\": [\n",
      "                                {\n",
      "                                    \"accession\": \"SRR7093892\",\n",
      "                                    \"filename\": \"SRR7093892.fastq.gz\",\n",
      "                                    \"filetype\": \"fastq\",\n",
      "                                    \"filesize\": 894123233,\n",
      "                                    \"filenumber\": 1,\n",
      "                                    \"md5\": \"c8439a8388dd6b47a130854bd3eabbce\",\n",
      "                                    \"urltype\": \"ftp\",\n",
      "                                    \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR709/002/SRR7093892/SRR7093892.fastq.gz\"\n",
      "                                }\n",
      "                            ],\n",
      "                            \"aws\": [],\n",
      "                            \"gcp\": [],\n",
      "                            \"ncbi\": []\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ffq SRS3243030"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd1076-7f29-4001-b65a-52a9b7f36a00",
   "metadata": {},
   "source": [
    "I detail a more full example related to accession and accessing the metadata in json form [at the bottom of this post on Biostarts](https://www.biostars.org/p/9522636/#9608530).\n",
    "\n",
    "**That should be most of what you need for ffq use.**  \n",
    "See [the ffq Github repo](https://github.com/pachterlab/ffq) for more command examples.\n",
    "\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "The `bio` package is another package that offers access to metadata at the SRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35d78ce1-0626-4918-a3e2-d85f8cd302ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bio -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef054091-2d10-450a-9ad3-bad924d17f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"run_accession\": \"SRR17607594\",\n",
      "        \"sample_accession\": \"SAMN24891916\",\n",
      "        \"sample_alias\": \"CN25-T\",\n",
      "        \"sample_description\": \"Human sample from Homo sapiens\",\n",
      "        \"first_public\": \"2022-08-22\",\n",
      "        \"country\": \"\",\n",
      "        \"scientific_name\": \"Homo sapiens\",\n",
      "        \"fastq_bytes\": \"47696043951;33618545069\",\n",
      "        \"base_count\": \"163951599482\",\n",
      "        \"read_count\": \"542886091\",\n",
      "        \"library_name\": \"Single nuclei RNA-CN25-Tumor\",\n",
      "        \"library_strategy\": \"OTHER\",\n",
      "        \"library_source\": \"TRANSCRIPTOMIC SINGLE CELL\",\n",
      "        \"library_layout\": \"PAIRED\",\n",
      "        \"instrument_platform\": \"ILLUMINA\",\n",
      "        \"instrument_model\": \"Illumina HiSeq 4000\",\n",
      "        \"study_title\": \"Radial glial cell signatures with FGFR3 hypomethylation and overexpression characterize central neurocytoma\",\n",
      "        \"fastq_url\": [\n",
      "            \"https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR176/094/SRR17607594/SRR17607594_1.fastq.gz\",\n",
      "            \"https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR176/094/SRR17607594/SRR17607594_2.fastq.gz\"\n",
      "        ],\n",
      "        \"info\": \"48 GB, 34 GB files; 542.9 million reads; 163951.6 million sequenced bases\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!bio search SRR17607594"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa8096-b84a-4f71-a7e1-51df54b28957",
   "metadata": {},
   "source": [
    "**That should be most of what you need for bio use.**  \n",
    "See [the bio package documentation](https://www.bioinfo.help/) for more command examples.\n",
    "\n",
    "#### Compare and contrast some examples of `ffq` & `bio search` use\n",
    "\n",
    "I do note that there's some advantages to each of them in certain ways.   \n",
    "I'll show some examples of each in turn to contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eef08cf9-68bd-4d08-9e32-c16a25eaaf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-17 02:21:24,174]    INFO Parsing run SRR23849628\n",
      "{\n",
      "    \"SRR23849628\": {\n",
      "        \"accession\": \"SRR23849628\",\n",
      "        \"experiment\": \"SRX19662564\",\n",
      "        \"study\": \"SRP410260\",\n",
      "        \"sample\": \"SRS17033009\",\n",
      "        \"title\": \"PromethION sequencing; GSM7093690: 35cycle_10X; Homo sapiens; RNA-Seq\",\n",
      "        \"attributes\": {\n",
      "            \"ENA-FIRST-PUBLIC\": \"2023-06-23\",\n",
      "            \"ENA-LAST-UPDATE\": \"2023-06-23\"\n",
      "        },\n",
      "        \"files\": {\n",
      "            \"ftp\": [\n",
      "                {\n",
      "                    \"accession\": \"SRR23849628\",\n",
      "                    \"filename\": \"SRR23849628_1.fastq.gz\",\n",
      "                    \"filetype\": \"fastq\",\n",
      "                    \"filesize\": 10790875511,\n",
      "                    \"filenumber\": 1,\n",
      "                    \"md5\": \"05b77f9a3d01bd63e66b796c16e86b90\",\n",
      "                    \"urltype\": \"ftp\",\n",
      "                    \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR238/028/SRR23849628/SRR23849628_1.fastq.gz\"\n",
      "                }\n",
      "            ],\n",
      "            \"aws\": [],\n",
      "            \"gcp\": [],\n",
      "            \"ncbi\": []\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ffq SRR23849628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b9c82d-c7bf-43ec-af00-3cabc52f1a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"run_accession\": \"SRR23849628\",\n",
      "        \"sample_accession\": \"SAMN33743856\",\n",
      "        \"sample_alias\": \"GSM7093690\",\n",
      "        \"sample_description\": \"35cycle_10X\",\n",
      "        \"first_public\": \"2023-06-23\",\n",
      "        \"country\": \"missing\",\n",
      "        \"scientific_name\": \"Homo sapiens\",\n",
      "        \"fastq_bytes\": \"10790875511\",\n",
      "        \"base_count\": \"10715195111\",\n",
      "        \"read_count\": \"6444874\",\n",
      "        \"library_name\": \"GSM7093690\",\n",
      "        \"library_strategy\": \"RNA-Seq\",\n",
      "        \"library_source\": \"TRANSCRIPTOMIC\",\n",
      "        \"library_layout\": \"SINGLE\",\n",
      "        \"instrument_platform\": \"OXFORD_NANOPORE\",\n",
      "        \"instrument_model\": \"PromethION\",\n",
      "        \"study_title\": \"Counting and correcting errors within unique molecular identifiers to generate absolute numbers of sequencing molecules [scRNA-Seq]\",\n",
      "        \"fastq_url\": [\n",
      "            \"https://ftp.sra.ebi.ac.uk/vol1/fastq/SRR238/028/SRR23849628/SRR23849628_1.fastq.gz\"\n",
      "        ],\n",
      "        \"info\": \"11 GB files; 6.4 million reads; 10715.2 million sequenced bases\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!bio search SRR23849628"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39990f3-c303-4edc-85f3-a70193070191",
   "metadata": {},
   "source": [
    "Note the `bio search` command reports number of reads as 6.4 million.  \n",
    "In this case `bio` doesn't give the source of the data as clear as `ffq` does. It is atypical, though as seen from the unrelated example `!bio search SRR17607594` executed as the first `bio search` example above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28af80c0-4b59-4a7b-b47f-87833afc4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-17 02:21:26,507]    INFO Parsing run ERR5670887\n",
      "{\n",
      "    \"ERR5670887\": {\n",
      "        \"accession\": \"ERR5670887\",\n",
      "        \"experiment\": \"ERX5386380\",\n",
      "        \"study\": \"ERP125915\",\n",
      "        \"sample\": \"ERS6200127\",\n",
      "        \"title\": \"MinION sequencing\",\n",
      "        \"attributes\": {\n",
      "            \"ENA-FIRST-PUBLIC\": \"2021-07-01\",\n",
      "            \"ENA-LAST-UPDATE\": \"2021-07-01\"\n",
      "        },\n",
      "        \"files\": {\n",
      "            \"ftp\": [],\n",
      "            \"aws\": [],\n",
      "            \"gcp\": [],\n",
      "            \"ncbi\": []\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ffq ERR5670887"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45c6f2-9f5c-4ff7-9cec-e38109c363cc",
   "metadata": {},
   "source": [
    "`ffq` will typically offer you more options for retrieval. Even in cases where other options exist, `bio search` won't feature the other URLs, at least currently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f9047a-bd22-4751-82a0-1b6b23518af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"run_accession\": \"ERR5670887\",\n",
      "        \"sample_accession\": \"SAMEA8515329\",\n",
      "        \"sample_alias\": \"OC43-MRC5-STM2120\",\n",
      "        \"sample_description\": \"MRC5 cells infected with HCoV-OC43 at an MOI of 3 for 24 hrs in the presence of STM2120\",\n",
      "        \"first_public\": \"2021-07-01\",\n",
      "        \"country\": \"\",\n",
      "        \"scientific_name\": \"Homo sapiens\",\n",
      "        \"fastq_bytes\": \"\",\n",
      "        \"base_count\": \"0\",\n",
      "        \"read_count\": \"0\",\n",
      "        \"library_name\": \"OC43-MRC5-STM2120-biorep1\",\n",
      "        \"library_strategy\": \"OTHER\",\n",
      "        \"library_source\": \"TRANSCRIPTOMIC\",\n",
      "        \"library_layout\": \"SINGLE\",\n",
      "        \"instrument_platform\": \"OXFORD_NANOPORE\",\n",
      "        \"instrument_model\": \"MinION\",\n",
      "        \"study_title\": \"Targeting the m6A RNA modification pathway blocks SARS-CoV-2 and HCoV-OC43 replication\",\n",
      "        \"bio_error\": \"invalid data: could not convert string to float: ''\",\n",
      "        \"fastq_url\": [\n",
      "            \"https://\"\n",
      "        ],\n",
      "        \"info\": \"0 files; 0.0 million reads; 0.0 million sequenced bases\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!bio search ERR5670887"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390361ff-df4d-4c61-9a15-15b81b643d1f",
   "metadata": {},
   "source": [
    "Note `bio search ERR5670887` gives no URL, unlike the result from `ffq`. Also, observe no number of reads reported even though there's 451,214 reads according to [SRA's RUN page for `ERR5670887` ](https://trace.ncbi.nlm.nih.gov/Traces/?view=run_browser&page_size=10&acc=ERR5670887&display=reads)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57968169-246a-4e7b-bf09-a0c2343328a5",
   "metadata": {},
   "source": [
    "That should cover most of what you need for `ffq` and `bio` use.\n",
    "\n",
    "However, if you need options for calling ffq when using on remote machines where the command line invocation isn't quite working as expected, or you want to integrate it with Python without calling the command line version since it is written in Python, read on for some options....\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "`ffq` normally gets installed in `bin` that can bre referenced if you needed to call it directly and `ffq` wasn't in the path because remote machine use. Here's where you'd invoke directly here to give you an idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e066fe-81bc-48f1-92a0-5c6c5d7f38e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ffq [-h] [-o OUT] [-l LEVEL] [--ftp] [--aws] [--gcp] [--ncbi] [--split]\n",
      "           [--verbose] [--version]\n",
      "           IDs [IDs ...]\n",
      "\n",
      "ffq 0.3.1: A command line tool to find sequencing data from SRA / GEO / ENCODE\n",
      "/ ENA / EBI-EMBL / DDBJ / Biosample.\n",
      "\n",
      "positional arguments:\n",
      "  IDs         One or multiple SRA / GEO / ENCODE / ENA / EBI-EMBL / DDBJ /\n",
      "              Biosample accessions, DOIs, or paper titles\n",
      "\n",
      "options:\n",
      "  -h, --help  Show this help message and exit\n",
      "  -o OUT      Path to write metadata (default: standard out)\n",
      "  -l LEVEL    Max depth to fetch data within accession tree\n",
      "  --ftp       Return FTP links\n",
      "  --aws       Return AWS links\n",
      "  --gcp       Return GCP links\n",
      "  --ncbi      Return NCBI links\n",
      "  --split     Split output into separate files by accession (`-o` is a\n",
      "              directory)\n",
      "  --verbose   Print debugging information\n",
      "  --version   show program's version number and exit\n"
     ]
    }
   ],
   "source": [
    "!/srv/conda/envs/notebook/bin/ffq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3798e6a4-2d54-4425-85cd-0c9380b2ac1d",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aba86db-44d8-4840-9fb1-8464aa7403f7",
   "metadata": {},
   "source": [
    "## Running ffq from inside Python\n",
    "\n",
    "ffq seems to run on the command line but I had considered using it inside remote machines where for some reason I didn't have access to the command line version. (Although maybe it was in `/bin/` on the machine somewhere and I could point at it with an absolute path? I found on MyBinder, you can point directly at `!/srv/conda/envs/notebook/bin/ffq`). So I was looking to use Python and found some ways. This could be useful, too, for adapting to code in situations, and so I include it here...\n",
    "\n",
    "Besides since `ffq` is Python-based, it would be nice to have a way to use `ffq` alongside Python without resorting to using `os.system()` and handling getting the output back into Python objects.\n",
    "\n",
    "Worked out how to run `ffq` equivalent fom inside Python in a session from a launch from [the binder project's 'simple `requirements.txt` based example' repo here](https://github.com/binder-examples/requirements) June 2023. (I thought it wasn't working the other day from MyBinder, and so I was actually surprised it worked to get the result. At the time, I found now it is working to get the metadata I was developing something and so just trying to get to the point I expected it to time out. Maybe there was an issue the other day with the service `ffq` accesses.)\n",
    "\n",
    "Note that in theory [ffq-api](https://github.com/seqeralabs/ffq-api) used via curl could allow me to use ffq not from the command line in inside OSG and the OSPool. However, I found the current public instance doesn't seem updated or doesn't have all the information that `ffq` makes available. I'll demonstrate that at the bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36c38e-a324-44bc-9f7a-3f362a474d74",
   "metadata": {},
   "source": [
    "---------\n",
    "\n",
    "### Updated options: Option 1 use a script or code where import it and then give arrguments via `sys.argv()`\n",
    "\n",
    "I had worked this out to try and use on the command line in execute node of OSG OSPool some of the deepTools' scripts that don't have the `if __name__ == \"__main__\"` as part of their code [The ones with can just be called with `python -m` with the arguments after, like `python -m deeptools.bamCompare --help`], consulting with Claude.ai for some options for these more complex cases where cannot use `python -m`. Claude had suggested use of `sys.argv`. Note you have to account for the first argument from the command line argument list actually being the name of the command called on the command line. (Note that since sys.argv using by default by `main()` here you don't need to feed it in, unlike I had been doing with `parser.parse_args()`, see below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7b27a0-ded7-4ceb-be7a-dcf607bf534a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:26,845]    INFO Parsing Experiment ERX5777701\n",
      "[2025-04-16 19:58:27,020] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:27,164] WARNING There is 1 run for ERX5777701\n",
      "[2025-04-16 19:58:27,165]    INFO Parsing run ERR6140859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"accession\": \"ERR6140859\",\n",
      "        \"filename\": \"ERR6140859_1.fastq.gz\",\n",
      "        \"filetype\": \"fastq\",\n",
      "        \"filesize\": 46548794,\n",
      "        \"filenumber\": 1,\n",
      "        \"md5\": \"87fbe7c5b04a66a8f17da0f16bb6bf36\",\n",
      "        \"urltype\": \"ftp\",\n",
      "        \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz\"\n",
      "    },\n",
      "    {\n",
      "        \"accession\": \"ERR6140859\",\n",
      "        \"filename\": \"ERR6140859_2.fastq.gz\",\n",
      "        \"filetype\": \"fastq\",\n",
      "        \"filesize\": 48630523,\n",
      "        \"filenumber\": 2,\n",
      "        \"md5\": \"49a6698e9c9099f21f6ace7953925027\",\n",
      "        \"urltype\": \"ftp\",\n",
      "        \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from ffq.main import main\n",
    "sys.argv = ['ffq','--ftp', 'ERX5777701']\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1873d-b510-4f68-86e4-43a3b3a95385",
   "metadata": {},
   "source": [
    "As I pointed out above you'll note that the first argument doesn't get consumed by the `main()` ffq, just like it doesn't behind the scenes when run on the command line but that you have to account for the first one in the list being the name of the command called on the command line. In other words in the example here it doesn't get used even though it is passed in. And so it is actually moot whatever you have there as long as you have something there as a placeholder to have the agruments start at the position after the first. Illustrating that with a nonsensical example as the first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d29e93c-35c0-473d-9722-6eb3ee86b8fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:28,201]    INFO Parsing Experiment ERX5777701\n",
      "[2025-04-16 19:58:28,210] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:28,211] WARNING There is 1 run for ERX5777701\n",
      "[2025-04-16 19:58:28,211]    INFO Parsing run ERR6140859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ERX5777701\": {\n",
      "        \"accession\": \"ERX5777701\",\n",
      "        \"title\": \"Fly Cell Atlas: single-cell transcriptomes of the entire adult Drosophila - Smartseq2 dataset\",\n",
      "        \"platform\": \"ILLUMINA\",\n",
      "        \"instrument\": \"Illumina NovaSeq 6000\",\n",
      "        \"runs\": {\n",
      "            \"ERR6140859\": {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"experiment\": \"ERX5777701\",\n",
      "                \"study\": \"ERP130174\",\n",
      "                \"sample\": \"ERS7029664\",\n",
      "                \"title\": \"Illumina NovaSeq 6000 paired end sequencing; Fly Cell Atlas: single-cell transcriptomes of the entire adult Drosophila - Smartseq2 dataset\",\n",
      "                \"attributes\": {\n",
      "                    \"ENA-FIRST-PUBLIC\": \"2021-07-02\",\n",
      "                    \"ENA-LAST-UPDATE\": \"2021-07-02\"\n",
      "                },\n",
      "                \"files\": {\n",
      "                    \"ftp\": [\n",
      "                        {\n",
      "                            \"accession\": \"ERR6140859\",\n",
      "                            \"filename\": \"ERR6140859_1.fastq.gz\",\n",
      "                            \"filetype\": \"fastq\",\n",
      "                            \"filesize\": 46548794,\n",
      "                            \"filenumber\": 1,\n",
      "                            \"md5\": \"87fbe7c5b04a66a8f17da0f16bb6bf36\",\n",
      "                            \"urltype\": \"ftp\",\n",
      "                            \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz\"\n",
      "                        },\n",
      "                        {\n",
      "                            \"accession\": \"ERR6140859\",\n",
      "                            \"filename\": \"ERR6140859_2.fastq.gz\",\n",
      "                            \"filetype\": \"fastq\",\n",
      "                            \"filesize\": 48630523,\n",
      "                            \"filenumber\": 2,\n",
      "                            \"md5\": \"49a6698e9c9099f21f6ace7953925027\",\n",
      "                            \"urltype\": \"ftp\",\n",
      "                            \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz\"\n",
      "                        }\n",
      "                    ],\n",
      "                    \"aws\": [],\n",
      "                    \"gcp\": [],\n",
      "                    \"ncbi\": []\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from ffq.main import main\n",
    "sys.argv = ['superMOOT','ERX5777701']\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace3a41-30c0-4e47-aef2-7bc23746f84b",
   "metadata": {
    "tags": []
   },
   "source": [
    "(SIDENOTE, these links can be used in combination with `curl` on MyBinder to retrieve the fastq files eventhough the ftp port is blocked. Turns out you can just change the `curl -OL ftp:/` to `curl -OL https:/`.)\n",
    "\n",
    "You can really see that first item in the arguments list coming from the command by running this example from https://stackoverflow.com/a/76443894/8508004 , which also was the source of the trick to put the arguments after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47d8fa7e-5af0-4ddb-be74-affa9f62e892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '-c'], ['1', 'a'], ['2', 'b'], ['3', 'c']]\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import sys; print([[str(x),a] for x,a in enumerate(sys.argv)])\" a b c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adce7b4-088e-4660-92bf-4ebf55350841",
   "metadata": {},
   "source": [
    "There the `-c` from the command gets consumed as the first argument in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772ffd3-6cf1-4abb-8f1b-7cb841c655bd",
   "metadata": {},
   "source": [
    "### Updated options: Option 2 use `python -c` to run on command line from inside Python \n",
    "\n",
    "Note that I worked out that for ffq this, `python -c \"from ffq.main import main; main()\"`,  will work to give USAGE information. (I had worked this out to try and use on the command line in execute node of OSG OSPool some of the deepTools' scripts that don't have the ``if __name__ == \"__main__\"` as part of their code [The ones with can just be called with `python -m` with the arguments after, like `python -m deeptools.bamCompare --help`], consulting with Claude.ai for some options for these more complex cases where cannot use `python -m`. ). Adding in the trick of using https://stackoverflow.com/a/76443894/8508004 I should be able to put the arguments after that, too, in order to run with arguments and not just get USAGE!\n",
    "                                                     \n",
    "                                                     \n",
    "I believe this will also work on OSG OSPool but there it'll be `python3 -c`.\n",
    "\n",
    "In action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d898c01-e7b6-4601-95a7-4a8250ce4bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:29,629]    INFO Parsing Experiment ERX5777701\n",
      "[2025-04-16 19:58:29,796] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:29,929] WARNING There is 1 run for ERX5777701\n",
      "[2025-04-16 19:58:29,929]    INFO Parsing run ERR6140859\n",
      "[\n",
      "    {\n",
      "        \"accession\": \"ERR6140859\",\n",
      "        \"filename\": \"ERR6140859_1.fastq.gz\",\n",
      "        \"filetype\": \"fastq\",\n",
      "        \"filesize\": 46548794,\n",
      "        \"filenumber\": 1,\n",
      "        \"md5\": \"87fbe7c5b04a66a8f17da0f16bb6bf36\",\n",
      "        \"urltype\": \"ftp\",\n",
      "        \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz\"\n",
      "    },\n",
      "    {\n",
      "        \"accession\": \"ERR6140859\",\n",
      "        \"filename\": \"ERR6140859_2.fastq.gz\",\n",
      "        \"filetype\": \"fastq\",\n",
      "        \"filesize\": 48630523,\n",
      "        \"filenumber\": 2,\n",
      "        \"md5\": \"49a6698e9c9099f21f6ace7953925027\",\n",
      "        \"urltype\": \"ftp\",\n",
      "        \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from ffq.main import main; main()\" --ftp ERX5777701"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d085bd0d-60c1-4075-8fcc-49de2d5842c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "---------\n",
    "\n",
    "### EARLIER OPTION I had worked out based on pasting and adapting source code for ffq - THIS IS WAY MORE COMPLEX THAN  ABOVE BECAUSE HAVE TO DIG THROUGH PERTINENT CODE AND ADD IT HERE IN ADAPTED FORM (so if updated significantly in subsequentdevelopment, you miss out or have to do again)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328e462-9ee2-4509-acdc-1f54c8efb602",
   "metadata": {},
   "source": [
    "Based on https://github.com/pachterlab/ffq/blob/898f56b0b9a07f152d2771fbb5157bf928febf4f/ffq/main.py and that I had seen `from ffq.main import run_ffq` work when I was inside Python running on OSG where I had also installed ffq in the environment \n",
    "\n",
    "Sending the arguments based on https://docs.python.org/3/library/argparse.html, especially [the 'Parsing arguments' section](https://docs.python.org/3/library/argparse.html#parsing-arguments) that fortunately shows how to pass the equivalents in of when you call something from the command line with arguments, which reminds me of `sh` module use in Python:\n",
    "\n",
    "```python\n",
    "parser.parse_args(['--sum', '7', '-1', '42'])\n",
    "```\n",
    "\n",
    "### The next two cells demonstrate running ffq from inside Python code!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a117ee7f-5617-48b1-ae7f-b758b0609c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------MOST OF THESE SECTIONS ADAPTED FROM THE SOURCE CODE--------------------------------------------------\n",
    "\n",
    "import argparse\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "#------First section mainly from `ffq/ffq/ffq.py`-------------------------------------------------------------\n",
    "# TODO evenetually [Sic] create an accession class\n",
    "# TODO better handling DOI parsing\n",
    "def validate_accessions(accessions, search_types):\n",
    "    # 1. extract the prefix 2. determine if prefix is valid or its a DOI\n",
    "    # {accession: str, prefix: str, valid: bool}\n",
    "\n",
    "    IDs = []\n",
    "    for input_accession in accessions:\n",
    "        # encode needs :3 ?\n",
    "        # bioproject needs :3 ?\n",
    "        # biosample needs :4 or : 5 ?\n",
    "        accession = input_accession.upper()\n",
    "\n",
    "        valid = False\n",
    "        prefix = re.findall(r\"(\\D+).+\", accession)[0]\n",
    "\n",
    "        if prefix in search_types:\n",
    "            valid = True\n",
    "\n",
    "        elif DOI_PARSER.match(accession) is not None:\n",
    "            valid = True\n",
    "            logger.warning(\"Searching by DOI may result in missing information.\")\n",
    "            prefix = \"DOI\"\n",
    "        else:\n",
    "            prefix = \"UNKNOWN\"\n",
    "        # TODO add error if not valid\n",
    "\n",
    "        IDs.append(\n",
    "            {\"accession\": accession, \"prefix\": prefix, \"valid\": valid, \"error\": None}\n",
    "        )\n",
    "\n",
    "    return IDs\n",
    "\n",
    "\n",
    "def parse_run(soup):\n",
    "    \"\"\"Given a BeautifulSoup object representing a run, parse out relevant\n",
    "    information.\n",
    "\n",
    "    :param soup: a BeautifulSoup object representing a run\n",
    "    :type soup: bs4.BeautifulSoup\n",
    "\n",
    "    :return: a dictionary containing run information\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    accession = soup.find(\"PRIMARY_ID\", text=RUN_PARSER).text\n",
    "    experiment = (\n",
    "        soup.find(\"PRIMARY_ID\", text=EXPERIMENT_PARSER).text\n",
    "        if soup.find(\"PRIMARY_ID\", text=EXPERIMENT_PARSER)\n",
    "        else soup.find(\"EXPERIMENT_REF\")[\"accession\"]\n",
    "    )\n",
    "\n",
    "    study_parsed = soup.find(\"ID\", text=PROJECT_PARSER)\n",
    "    if study_parsed:\n",
    "        study = study_parsed.text\n",
    "    else:\n",
    "        #     logger.warning(\n",
    "        #         'Failed to parse study information from ENA XML. Falling back to '\n",
    "        #         'ENA search...'\n",
    "        #     )\n",
    "        study = search_ena_run_study(accession)\n",
    "    sample_parsed = soup.find(\"ID\", text=SAMPLE_PARSER)\n",
    "    if sample_parsed:\n",
    "        sample = sample_parsed.text\n",
    "    else:\n",
    "        # logger.warning(\n",
    "        #     'Failed to parse sample information from ENA XML. Falling back to '\n",
    "        #     'ENA search...'\n",
    "        # )\n",
    "        sample = search_ena_run_sample(accession)\n",
    "    title = soup.find(\"TITLE\").text\n",
    "\n",
    "    attributes = {}\n",
    "\n",
    "    for attr in soup.find_all(\"RUN_ATTRIBUTE\"):\n",
    "        try:\n",
    "            tag = attr.find(\"TAG\").text\n",
    "            value = attr.find(\"VALUE\").text\n",
    "            attributes[tag] = value\n",
    "        except:  # noqa\n",
    "            pass\n",
    "    if attributes:\n",
    "        try:\n",
    "            attributes[\"ENA-SPOT-COUNT\"] = int(attributes[\"ENA-SPOT-COUNT\"])\n",
    "            attributes[\"ENA-BASE-COUNT\"] = int(attributes[\"ENA-BASE-COUNT\"])\n",
    "        except:  # noqa\n",
    "            pass\n",
    "    ftp_files = get_files_metadata_from_run(soup)\n",
    "    # print(ftp_files)\n",
    "    # ftp_files = [file for file in ftp_files if accession in file['url']]\n",
    "    # print(ftp_files)\n",
    "    # for file in ftp_files:\n",
    "    #     if accession in file['url']:\n",
    "    # url, md5, size =file['url'], file['md5'], file['size']\n",
    "    # # we want url last, so we delete they key and include it later\n",
    "    # del file['url'], file['md5'], file['size']\n",
    "    # filetype, fileno = parse_url(file['url'])\n",
    "    # file['filetype'] = filetype\n",
    "    # file['filenumber'] = fileno\n",
    "\n",
    "    alt_links_soup = ncbi_fetch_fasta(accession, \"sra\")\n",
    "\n",
    "    aws_links = parse_ncbi_fetch_fasta(alt_links_soup, \"AWS\")\n",
    "    aws_results = []\n",
    "    for url in aws_links:\n",
    "        if accession in url:\n",
    "            filetype, fileno = parse_url(url)\n",
    "            aws_results.append(\n",
    "                {\n",
    "                    \"accession\": accession,\n",
    "                    \"filename\": url.split(\"/\")[-1],\n",
    "                    \"filetype\": filetype,\n",
    "                    \"filesize\": None,\n",
    "                    \"filenumber\": fileno,\n",
    "                    \"md5\": None,\n",
    "                    \"urltype\": \"aws\",\n",
    "                    \"url\": url,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    gcp_links = parse_ncbi_fetch_fasta(alt_links_soup, \"GCP\")\n",
    "    gcp_results = []\n",
    "    for url in gcp_links:\n",
    "        if accession in url:\n",
    "            filetype, fileno = parse_url(url)\n",
    "            gcp_results.append(\n",
    "                {\n",
    "                    \"accession\": accession,\n",
    "                    \"filename\": url.split(\"/\")[-1],\n",
    "                    \"filetype\": filetype,\n",
    "                    \"filesize\": None,\n",
    "                    \"filenumber\": fileno,\n",
    "                    \"md5\": None,\n",
    "                    \"urltype\": \"gcp\",\n",
    "                    \"url\": url,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    ncbi_links = parse_ncbi_fetch_fasta(alt_links_soup, \"NCBI\")\n",
    "    ncbi_results = []\n",
    "    for url in ncbi_links:\n",
    "        if accession in url:\n",
    "            filetype, fileno = parse_url(url)\n",
    "            ncbi_results.append(\n",
    "                {\n",
    "                    \"accession\": accession,\n",
    "                    \"filename\": url.split(\"/\")[-1],\n",
    "                    \"filetype\": filetype,\n",
    "                    \"filesize\": None,\n",
    "                    \"filenumber\": fileno,\n",
    "                    \"md5\": None,\n",
    "                    \"urltype\": \"ncbi\",\n",
    "                    \"url\": url,\n",
    "                }\n",
    "            )\n",
    "    files = {\n",
    "        \"ftp\": ftp_files,\n",
    "        \"aws\": aws_results,\n",
    "        \"gcp\": gcp_results,\n",
    "        \"ncbi\": ncbi_results,\n",
    "    }\n",
    "    return {\n",
    "        \"accession\": accession,\n",
    "        \"experiment\": experiment,\n",
    "        \"study\": study,\n",
    "        \"sample\": sample,\n",
    "        \"title\": title,\n",
    "        \"attributes\": attributes,\n",
    "        \"files\": files,\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_sample(soup):\n",
    "    \"\"\"Given a BeautifulSoup object representing a sample, parse out relevant\n",
    "    information.\n",
    "\n",
    "    :param soup: a BeautifulSoup object representing a sample\n",
    "    :type soup: bs4.BeautifulSoup\n",
    "\n",
    "    :return: a dictionary containing sample information\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    accession = soup.find(\"PRIMARY_ID\", text=SAMPLE_PARSER).text\n",
    "    title = soup.find(\"TITLE\").text\n",
    "    organism = soup.find(\"SCIENTIFIC_NAME\").text\n",
    "    sample_attribute = soup.find_all(\"SAMPLE_ATTRIBUTE\")\n",
    "    try:\n",
    "        attributes = {\n",
    "            attr.find(\"TAG\").text: attr.find(\"VALUE\").text for attr in sample_attribute\n",
    "        }\n",
    "    except:  # noqa\n",
    "        attributes = \"\"\n",
    "    if attributes:\n",
    "        try:\n",
    "            attributes[\"ENA-SPOT-COUNT\"] = int(attributes[\"ENA-SPOT-COUNT\"])\n",
    "            attributes[\"ENA-BASE-COUNT\"] = int(attributes[\"ENA-BASE-COUNT\"])\n",
    "        except:  # noqa\n",
    "            pass\n",
    "    try:\n",
    "\n",
    "        experiment = soup.find(\n",
    "            re.compile(r\"PRIMARY_ID|ID\"), text=EXPERIMENT_PARSER\n",
    "        ).text\n",
    "        # try:\n",
    "        #     experiment = soup.find('ID', text=EXPERIMENT_PARSER).text\n",
    "        # except:  # noqa\n",
    "        #     experiment = soup.find('PRIMARY_ID', text=EXPERIMENT_PARSER).text\n",
    "\n",
    "    except:  # noqa\n",
    "        logger.warning(\n",
    "            \"Failed to parse sample information from ENA XML. Falling back to \"\n",
    "            \"ENA search...\"\n",
    "        )\n",
    "        try:\n",
    "            experiment = search_ena(\n",
    "                accession,\n",
    "                \"secondary_sample_accession\",\n",
    "                \"read_experiment\",\n",
    "                \"experiment_accession\",\n",
    "            )[0]\n",
    "\n",
    "        except:  # noqa\n",
    "            experiment = \"\"\n",
    "            logger.warning(\"No experiment found\")\n",
    "\n",
    "    return {\n",
    "        \"accession\": accession,\n",
    "        \"title\": title,\n",
    "        \"organism\": organism,\n",
    "        \"attributes\": attributes,\n",
    "        \"experiments\": experiment,\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_experiment_with_run(soup, level):\n",
    "    \"\"\"Given a BeautifulSoup object representing an experiment, parse out relevant\n",
    "    information.\n",
    "\n",
    "    :param soup: a BeautifulSoup object representing an experiment\n",
    "    :type soup: bs4.BeautifulSoup\n",
    "\n",
    "    :param l: positive integer representing how many downstream accession levels should be fetched.\n",
    "    :type l: int\n",
    "\n",
    "    :return: a dictionary containing experiment information\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    accession = soup.find(\"PRIMARY_ID\", text=EXPERIMENT_PARSER).text\n",
    "    title = soup.find(\"TITLE\").text\n",
    "    platform = soup.find(\"INSTRUMENT_MODEL\").find_parent().name\n",
    "    instrument = soup.find(\"INSTRUMENT_MODEL\").text\n",
    "\n",
    "    experiment = {\n",
    "        \"accession\": accession,\n",
    "        \"title\": title,\n",
    "        \"platform\": platform,\n",
    "        \"instrument\": instrument,\n",
    "    }\n",
    "    if level is None or level > 1:\n",
    "        # Returns all of the runs associated with an experiment\n",
    "        runs = srx_to_srrs(accession)\n",
    "        if len(runs) == 1:\n",
    "            logger.warning(f\"There is 1 run for {accession}\")\n",
    "\n",
    "        else:\n",
    "            logger.warning(f\"There are {len(runs)} runs for {accession}\")\n",
    "\n",
    "        runs = {run: ffq_run(run) for run in runs}\n",
    "\n",
    "        experiment.update({\"runs\": runs})\n",
    "        return experiment\n",
    "    else:\n",
    "        return experiment\n",
    "\n",
    "\n",
    "def parse_study(soup):\n",
    "    \"\"\"Given a BeautifulSoup object representing a study, parse out relevant\n",
    "    information.\n",
    "\n",
    "    :param soup: a BeautifulSoup object representing a study\n",
    "    :type soup: bs4.BeautifulSoup\n",
    "\n",
    "    :return: a dictionary containing study information\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    accession = soup.find(\"PRIMARY_ID\", text=PROJECT_PARSER).text\n",
    "    title = soup.find(\"STUDY_TITLE\").text\n",
    "    abstract = soup.find(\"STUDY_ABSTRACT\").text if soup.find(\"STUDY_ABSTRACT\") else \"\"\n",
    "    return {\"accession\": accession, \"title\": title, \"abstract\": abstract}\n",
    "\n",
    "\n",
    "def parse_gse_search(soup):\n",
    "    \"\"\"Given a BeautifulSoup object representing a geo study, parse out relevant\n",
    "    information.\n",
    "\n",
    "    :param soup: a BeautifulSoup object representing a study\n",
    "    :type soup: bs4.BeautifulSoup\n",
    "\n",
    "    :return: a dictionary containing geo study unique identifier based on a search\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    data = json.loads(soup.text)\n",
    "    if data[\"esearchresult\"][\"idlist\"]:\n",
    "        accession = data[\"esearchresult\"][\"querytranslation\"].split(\"[\")[0]\n",
    "        geo_id = data[\"esearchresult\"][\"idlist\"][-1]\n",
    "        return {\"accession\": accession, \"geo_id\": geo_id}\n",
    "    else:\n",
    "        raise InvalidAccession(\"Provided GSE accession is invalid\")\n",
    "\n",
    "\n",
    "def parse_gse_summary(soup):\n",
    "    \"\"\"Given a BeautifulSoup object representing a geo study identifier, parse out relevant\n",
    "    information.\n",
    "\n",
    "    :param soup: a BeautifulSoup object representing a study\n",
    "    :type soup: bs4.BeautifulSoup\n",
    "\n",
    "    :return: a dictionary containing summary of geo study information\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    data = json.loads(soup.text)\n",
    "\n",
    "    geo_id = data[\"result\"][\"uids\"][-1]\n",
    "\n",
    "    relations = data[\"result\"][f\"{geo_id}\"][\"extrelations\"]\n",
    "    for value in relations:\n",
    "        if value[\"relationtype\"] == \"SRA\":  # may have many samples?\n",
    "            sra = value\n",
    "\n",
    "    if sra:\n",
    "        srp = sra[\"targetobject\"]\n",
    "        return {\"accession\": srp}\n",
    "\n",
    "\n",
    "def ffq_run(accession, level=0):  # noqa\n",
    "    \"\"\"Fetch Run information.\n",
    "\n",
    "    :param accession: run accession (SRR, ERR or DRR)\n",
    "    :type accession: str\n",
    "\n",
    "    :return: dictionary of run information\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    logger.info(f\"Parsing run {accession}\")\n",
    "    run = parse_run(get_xml(accession))\n",
    "    return run\n",
    "\n",
    "\n",
    "def ffq_study(accession, level=None):\n",
    "    \"\"\"Fetch Study information.\n",
    "\n",
    "    :param accession: study accession (SRP, ERP or DRP)\n",
    "    :type accession: str\n",
    "\n",
    "    :param l: positive integer representing how many downstream accession levels should be fetched.\n",
    "    :type l: int\n",
    "\n",
    "    :return: dictionary of study information. The dictionary contains a\n",
    "             'samples' key, which is a dictionary of all the samples in the study, as\n",
    "             returned by `ffq_sample`.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    logger.info(f\"Parsing Study {accession}\")\n",
    "    study = parse_study(get_xml(accession))\n",
    "    if level is None or level != 1:\n",
    "        try:\n",
    "            level -= 1\n",
    "        except:  # noqa\n",
    "            pass\n",
    "        logger.info(f\"Getting Sample for {accession}\")\n",
    "        sample_ids = get_samples_from_study(accession)\n",
    "        logger.warning(f\"There are {str(len(sample_ids))} samples for {accession}\")\n",
    "        samples = [ffq_sample(sample_id, level) for sample_id in sample_ids]\n",
    "        study.update({\"samples\": {sample[\"accession\"]: sample for sample in samples}})\n",
    "        return study\n",
    "    else:\n",
    "        return study\n",
    "\n",
    "\n",
    "def ffq_gse(accession, level=None):\n",
    "    \"\"\"Fetch GSE information.\n",
    "\n",
    "    This function finds the GSMs corresponding to the GSE and calls `ffq_gsm`.\n",
    "\n",
    "    :param accession: GSE accession\n",
    "    :type accession: str\n",
    "\n",
    "    :param l: positive integer representing how many downstream accession levels should be fetched.\n",
    "    :type l: int\n",
    "\n",
    "    :return: dictionary containing GSE information. The dictionary contains a\n",
    "             'sample' key, which is a dictionary of all the GSMs in the study, as\n",
    "             returned by `ffq_gsm`.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    logger.info(f\"Parsing GEO {accession}\")\n",
    "    gse = parse_gse_search(get_gse_search_json(accession))\n",
    "    logger.info(f\"Finding supplementary files for GEO {accession}\")\n",
    "    time.sleep(1)\n",
    "    supp = geo_to_suppl(accession, \"GSE\")\n",
    "    if len(supp) > 0:\n",
    "        gse.update({\"supplementary_files\": supp})\n",
    "    else:\n",
    "        logger.info(f\"No supplementary files found for {accession}\")\n",
    "    gse.pop(\"geo_id\")\n",
    "    if level is None or level != 1:\n",
    "        try:\n",
    "            level -= 1\n",
    "        except:  # noqa\n",
    "            pass\n",
    "        time.sleep(1)\n",
    "        gsm_ids = gse_to_gsms(accession)\n",
    "        logger.warning(f\"There are {str(len(gsm_ids))} samples for {accession}\")\n",
    "        gsms = [ffq_gsm(gsm_id, level) for gsm_id in gsm_ids]\n",
    "        gse.update({\"geo_samples\": {sample[\"accession\"]: sample for sample in gsms}})\n",
    "        return gse\n",
    "    else:\n",
    "        return gse\n",
    "\n",
    "\n",
    "def ffq_gsm(accession, level=None):\n",
    "    \"\"\"Fetch GSM information.\n",
    "\n",
    "    This function finds the SRS corresponding to the GSM and calls `ffq_sample`.\n",
    "\n",
    "    :param accession: GSM accession\n",
    "    :type accession: str\n",
    "\n",
    "    :param l: positive integer representing how many downstream accession levels should be fetched.\n",
    "    :type l: int\n",
    "\n",
    "    :return: dictionary containing GSM information. The dictionary contains a\n",
    "             'sample' key, which is a dictionary of the sample asssociated to the GSM, as\n",
    "             returned by `ffq_sample`.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    logger.info(f\"Parsing GSM {accession}\")\n",
    "    gsm = get_gsm_search_json(accession)\n",
    "    logger.info(f\"Finding supplementary files for GSM {accession}\")\n",
    "    time.sleep(1)\n",
    "    supp = geo_to_suppl(accession, \"GSM\")\n",
    "    if supp:\n",
    "        gsm.update({\"supplementary_files\": supp})\n",
    "    else:\n",
    "        logger.info(f\"No supplementary files found for {accession}\")\n",
    "\n",
    "    gsm.update(gsm_to_platform(accession))\n",
    "    if level is None or level != 1:\n",
    "        try:\n",
    "            level -= 1\n",
    "        except:  # noqa\n",
    "            pass\n",
    "        logger.info(f\"Getting sample for {accession}\")\n",
    "        srs = gsm_id_to_srs(gsm.pop(\"geo_id\"))\n",
    "        if srs:\n",
    "            sample = ffq_sample(srs, level)\n",
    "            gsm.update({\"samples\": {sample[\"accession\"]: sample}})\n",
    "        else:\n",
    "            return gsm\n",
    "        return gsm\n",
    "    else:\n",
    "        return gsm\n",
    "\n",
    "\n",
    "def ffq_experiment(accession, level=None):\n",
    "    \"\"\"Fetch Experiment information.\n",
    "\n",
    "    :param accession: experiment accession (SRX, ERX or DRX)\n",
    "    :type accession: str\n",
    "\n",
    "    :param l: positive integer representing how many downstream accession levels should be fetched.\n",
    "    :type l: int\n",
    "\n",
    "    :return: dictionary of experiment information. The dictionary contains a\n",
    "             'runs' key, which is a dictionary of all the runs in the study, as\n",
    "             returned by `ffq_run`.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    logger.info(f\"Parsing Experiment {accession}\")\n",
    "    experiment = parse_experiment_with_run(get_xml(accession), level)\n",
    "    return experiment\n",
    "\n",
    "\n",
    "def ffq_sample(accession, level=None):\n",
    "    \"\"\"Fetch Sample information.\n",
    "\n",
    "    :param accession: sample accession (SRS, ERS or DRS)\n",
    "    :type accession: str\n",
    "\n",
    "    :param l: positive integer representing how many downstream accession levels should be fetched.\n",
    "    :type l: int\n",
    "\n",
    "    :return: dictionary of sample information. The dictionary contains a\n",
    "             'runs' key, which is a dictionary of all the runs in the study, as\n",
    "             returned by `ffq_run`.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    logger.info(f\"Parsing sample {accession}\")\n",
    "    xml_sample = get_xml(accession)\n",
    "    sample = parse_sample(xml_sample)\n",
    "    if level is None or level != 1:\n",
    "        try:\n",
    "            level -= 1\n",
    "        except:  # noqa\n",
    "            pass\n",
    "        logger.info(f\"Getting Experiment for {accession}\")\n",
    "        exp_id = sample[\"experiments\"]\n",
    "        if not exp_id:\n",
    "            try:\n",
    "                alias = xml_sample.SAMPLE.attrs[\"alias\"]\n",
    "                id = get_gsm_search_json(alias)[\"geo_id\"]\n",
    "                exp_id = ncbi_summary(\"gds\", id)[id][\"extrelations\"][0][\"targetobject\"]\n",
    "            except:  # noqa\n",
    "                logger.warning(f\"No Experiment found for {accession}\")\n",
    "        if \",\" in exp_id:\n",
    "            exp_ids = exp_id.split(\",\")\n",
    "            experiments = [ffq_experiment(exp_id, level) for exp_id in exp_ids]\n",
    "            sample.update(\n",
    "                {\n",
    "                    \"experiments\": [\n",
    "                        {experiment[\"accession\"]: experiment}\n",
    "                        for experiment in experiments\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            return sample\n",
    "        else:\n",
    "            experiment = ffq_experiment(exp_id, level)\n",
    "            sample.update({\"experiments\": {experiment[\"accession\"]: experiment}})\n",
    "        return sample\n",
    "    else:\n",
    "        return sample\n",
    "\n",
    "\n",
    "def ffq_encode(accession, level=0):\n",
    "    \"\"\"Fetch ENCODE ids information. This\n",
    "    function receives an ENCSR, ENCBS or ENCD\n",
    "    ENCODE id and fetches the associated metadata\n",
    "\n",
    "    :param accession: an ENCODE id (ENCSR, ENCBS or ENCD)\n",
    "    :type accession: str\n",
    "\n",
    "    :return: dictionary of ENCODE id metadata.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    logger.info(f\"Parsing {accession}\")\n",
    "    encode = parse_encode_json(accession, get_encode_json(accession))\n",
    "    return encode\n",
    "\n",
    "\n",
    "def ffq_bioproject(accession, level=0):  # noqa\n",
    "    \"\"\"Fetch bioproject ids information. This\n",
    "    function receives a CXR accession\n",
    "    and fetches the associated metadata\n",
    "\n",
    "    :param accession: a bioproject CXR id\n",
    "    :type accession: str\n",
    "\n",
    "    :return: dictionary of bioproject metadata.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    return parse_bioproject(ena_fetch(accession, \"bioproject\"))\n",
    "\n",
    "\n",
    "def ffq_biosample(accession, level=None):\n",
    "    \"\"\"Fetch biosample ids information. This\n",
    "    function receives a SAMN accession\n",
    "    and fetches the associated metadata\n",
    "\n",
    "    :param accession: a biosample SAMN id\n",
    "    :type accession: str\n",
    "\n",
    "    :return: dictionary of biosample metadata.\n",
    "    :rtype: dict\n",
    "    \"\"\"\n",
    "    # commented below: old implementation using ncbi to fetch biosample data\n",
    "    # soup = ena_fetch(accession, 'biosample')\n",
    "    # sample = soup.find('id', text=SAMPLE_PARSER).text\n",
    "    soup = get_xml(accession)\n",
    "    sample = soup.SAMPLE.attrs[\"accession\"]\n",
    "    try:\n",
    "        level = level - 1\n",
    "    except:  # noqa\n",
    "        pass\n",
    "    sample_data = ffq_sample(sample, level)\n",
    "    return {\"accession\": accession, \"samples\": sample_data}\n",
    "\n",
    "\n",
    "def ffq_doi(doi, level=0):  # noqa\n",
    "    \"\"\"Fetch DOI information.\n",
    "\n",
    "    This function first searches CrossRef for the paper title, then uses that\n",
    "    to find any SRA studies that match the title. If there are, all the runs in\n",
    "    each study are fetched. If there are not, Pubmed is searched for the DOI,\n",
    "    which may contain GEO IDs. If there are GEO IDs, `ffq_gse` is called for each.\n",
    "    If not, the Pubmed entry may include SRA links. If there are, `ffq_run` is\n",
    "    called for each linked run. These runs are then grouped by SRP.\n",
    "\n",
    "    :param doi: paper DOI\n",
    "    :type doi: str\n",
    "\n",
    "    :return: list of SRA or GEO studies that are linked to this paper. If\n",
    "             there are SRA studies matching the paper title, the returned\n",
    "             list is a list of SRA studies. If not, and the paper includes\n",
    "             a GEO link, it is a list of GEO studies. If not, and the paper\n",
    "             includes SRA links, it is a list of SRPs.\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "    # Sanitize DOI so that it doesn't include leading http or https\n",
    "    parsed = urlparse(doi)\n",
    "\n",
    "    if parsed.scheme:\n",
    "        doi = parsed.path.strip(\"/\")\n",
    "\n",
    "    logger.info(f\"Searching for DOI '{doi}'\")\n",
    "    paper = get_doi(doi)\n",
    "    title = paper[\"title\"][0]\n",
    "\n",
    "    logger.info(f\"Searching for Study SRP with title '{title}'\")\n",
    "    study_accessions = search_ena_title(title)\n",
    "\n",
    "    if study_accessions:\n",
    "        logger.info(\n",
    "            f'Found {len(study_accessions)} studies that match this title: {\", \".join(study_accessions)}'\n",
    "        )\n",
    "        return [ffq_study(accession, None) for accession in study_accessions]\n",
    "\n",
    "    # If not study with the title is found, search Pubmed, which can be linked\n",
    "    # to a GEO accession.\n",
    "    logger.warning(\n",
    "        (\"No studies found with the given title. \" f\"Searching Pubmed for DOI '{doi}'\")\n",
    "    )\n",
    "    pubmed_ids = ncbi_search(\"pubmed\", doi)\n",
    "\n",
    "    if not pubmed_ids:\n",
    "        raise Exception(\"No Pubmed records match the DOI\")\n",
    "    if len(pubmed_ids) > 1:\n",
    "        raise Exception(f'{len(pubmed_ids)} match the DOI: {\", \".join(pubmed_ids)}')\n",
    "\n",
    "    pubmed_id = pubmed_ids[0]\n",
    "    logger.info(f\"Searching for GEO record linked to Pubmed ID '{pubmed_id}'\")\n",
    "    geo_ids = ncbi_link(\"pubmed\", \"gds\", pubmed_id)\n",
    "    if geo_ids:\n",
    "        # Convert these geo ids to GSE accessions\n",
    "        gses = geo_ids_to_gses(geo_ids)\n",
    "        logger.info(f'Found {len(gses)} GEO Accessions: {\", \".join(gses)}')\n",
    "        if len(gses) != len(geo_ids):\n",
    "            raise Exception(\n",
    "                (\n",
    "                    \"Number of GEO Accessions found does not match the number of GEO \"\n",
    "                    f\"records: expected {len(geo_ids)} but found {len(gses)}\"\n",
    "                )\n",
    "            )\n",
    "        # Sleep for 1sec because NCBI has rate-limiting to 3 requests/sec\n",
    "        time.sleep(1)\n",
    "        return [ffq_gse(accession) for accession in gses]\n",
    "\n",
    "    # If the pubmed id is not linked to any GEO record, search for SRA records\n",
    "    logger.warning(\n",
    "        (\n",
    "            f\"No GEO records are linked to the Pubmed ID '{pubmed_id}'. \"\n",
    "            \"Searching for SRA record linked to this Pubmed ID.\"\n",
    "        )\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    sra_ids = ncbi_link(\"pubmed\", \"sra\", pubmed_id)\n",
    "    if sra_ids:\n",
    "        srrs = sra_ids_to_srrs(sra_ids)\n",
    "        logger.warning(f\"Found {len(srrs)} run accessions.\")\n",
    "        runs = [ffq_run(accession) for accession in srrs]\n",
    "\n",
    "        # Group runs by project to keep things consistent.\n",
    "        studies = {}\n",
    "        for run in runs:\n",
    "            study = run[\"study\"].copy()  # Prevent recursive dict\n",
    "            # get the study accession if exists and add the run to the runs\n",
    "            studies.setdefault(study[\"accession\"], study).setdefault(\"runs\", {})[\n",
    "                run[\"accession\"]\n",
    "            ] = run\n",
    "\n",
    "        return [v for k, v in studies.items()]\n",
    "    else:\n",
    "        raise Exception(f\"No SRA records are linked to Pubmed ID '{pubmed_id}'\")\n",
    "\n",
    "        \n",
    "#--------ABOVE AND BELOW FROM DIFFERENT SOUCE IN THE SOURCE CODE------------------------------------------\n",
    "#------Next section mainly from `ffq/ffq/main.py`---------------------------------------------------------\n",
    "RUN_TYPES = (\n",
    "    \"SRR\",\n",
    "    \"ERR\",\n",
    "    \"DRR\",\n",
    ")\n",
    "PROJECT_TYPES = (\n",
    "    \"SRP\",\n",
    "    \"ERP\",\n",
    "    \"DRP\",\n",
    ")\n",
    "EXPERIMENT_TYPES = (\n",
    "    \"SRX\",\n",
    "    \"ERX\",\n",
    "    \"DRX\",\n",
    ")\n",
    "SAMPLE_TYPES = (\"SRS\", \"ERS\", \"DRS\", \"CRS\")\n",
    "GEO_TYPES = (\"GSE\", \"GSM\")\n",
    "ENCODE_TYPES = (\"ENCSR\", \"ENCBS\", \"ENCDO\")\n",
    "BIOPROJECT_TYPES = (\n",
    "    \"CRX\",\n",
    ")  # TODO implement CRR and CRP, most dont have public metadata.\n",
    "BIOSAMPLE_TYPES = (\"SAMN\", \"SAMD\", \"SAMEA\", \"SAMEG\")\n",
    "OTHER_TYPES = (\"DOI\",)\n",
    "SEARCH_TYPES = (\n",
    "    RUN_TYPES\n",
    "    + PROJECT_TYPES\n",
    "    + EXPERIMENT_TYPES\n",
    "    + SAMPLE_TYPES\n",
    "    + GEO_TYPES\n",
    "    + ENCODE_TYPES\n",
    "    + BIOPROJECT_TYPES\n",
    "    + BIOSAMPLE_TYPES\n",
    "    + OTHER_TYPES\n",
    ")\n",
    "\n",
    "# main ffq caller\n",
    "FFQ = {\n",
    "    \"DOI\": ffq_doi,\n",
    "    \"GSM\": ffq_gsm,\n",
    "    \"GSE\": ffq_gse,\n",
    "}\n",
    "FFQ.update({t: ffq_run for t in RUN_TYPES})\n",
    "FFQ.update({t: ffq_study for t in PROJECT_TYPES})\n",
    "FFQ.update({t: ffq_experiment for t in EXPERIMENT_TYPES})\n",
    "FFQ.update({t: ffq_sample for t in SAMPLE_TYPES})\n",
    "FFQ.update({t: ffq_encode for t in ENCODE_TYPES})\n",
    "FFQ.update({t: ffq_bioproject for t in BIOPROJECT_TYPES})\n",
    "FFQ.update({t: ffq_biosample for t in BIOSAMPLE_TYPES})\n",
    "\n",
    "RUN_PARSER = re.compile(r\"(SRR.+)|(ERR.+)|(DRR.+)\")\n",
    "EXPERIMENT_PARSER = re.compile(r\"(SRX.+)|(ERX.+)|(DRX.+)\")\n",
    "PROJECT_PARSER = re.compile(r\"(SRP.+)|(ERP.+)|(DRP.+)\")\n",
    "SAMPLE_PARSER = re.compile(r\"(SRS.+)|(ERS.+)|(DRS.+)\")\n",
    "DOI_PARSER = re.compile(\"^10.\\d{4,9}\\/[-._;()\\/:A-Z0-9]+\")  # noqa\n",
    "\n",
    "#--------ABOVE AND BELOW FROM DIFFERENT SOUCE IN THE SOURCE CODE----------------------------------------------------\n",
    "#------Next section adapted from `ffq/ffq/main.py` to set up the `args` to use with `run_ffq` imported below--------\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=(\n",
    "        (\n",
    "            f\"ffq : A command line tool to find sequencing data \"\n",
    "            \"from SRA / GEO / ENCODE / ENA / EBI-EMBL / DDBJ / Biosample.\"\n",
    "        )\n",
    "    )\n",
    ")\n",
    "parser._actions[0].help = parser._actions[0].help.capitalize()\n",
    "\n",
    "parser.add_argument(\n",
    "    \"IDs\",\n",
    "    help=(\n",
    "        \"One or multiple SRA / GEO / ENCODE / ENA / EBI-EMBL / DDBJ / Biosample accessions, \"\n",
    "        \"DOIs, or paper titles\"\n",
    "    ),\n",
    "    nargs=\"+\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"-o\",\n",
    "    metavar=\"OUT\",\n",
    "    help=(\"Path to write metadata (default: standard out)\"),\n",
    "    type=str,\n",
    "    required=False,\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"-t\",\n",
    "    metavar=\"TYPE\",\n",
    "    help=argparse.SUPPRESS,\n",
    "    type=str,\n",
    "    required=False,\n",
    "    choices=SEARCH_TYPES,\n",
    ")\n",
    "\n",
    "parser.add_argument(\n",
    "    \"-l\",\n",
    "    metavar=\"LEVEL\",\n",
    "    help=\"Max depth to fetch data within accession tree\",\n",
    "    type=int,\n",
    ")\n",
    "\n",
    "parser.add_argument(\"--ftp\", help=\"Return FTP links\", action=\"store_true\")\n",
    "\n",
    "parser.add_argument(\"--aws\", help=\"Return AWS links\", action=\"store_true\")  # noqa\n",
    "\n",
    "parser.add_argument(\"--gcp\", help=\"Return GCP links\", action=\"store_true\")  # noqa\n",
    "\n",
    "parser.add_argument(\"--ncbi\", help=\"Return NCBI links\", action=\"store_true\")  # noqa\n",
    "parser.add_argument(\n",
    "    \"--split\",\n",
    "    help=\"Split output into separate files by accession  (`-o` is a directory)\",  # noqa\n",
    "    action=\"store_true\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--verbose\", help=\"Print debugging information\", action=\"store_true\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--version\", action=\"version\", version=f\"%(prog)s 0.3\"\n",
    ")\n",
    "\n",
    "#--------ABOVE FROM THE SOURCE CODE--------------------------------------------------\n",
    "\n",
    "from ffq.main import run_ffq\n",
    "#run_ffq(parser.parse_args(['--ftp','ERX5777701'])) #<-- this works but makes more sense to have a set-up cell for code and then run equivalent process in its own cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3656051c-afbd-4464-bcf0-3a8fd2136649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:31,166]    INFO Parsing Experiment ERX5777701\n",
      "[2025-04-16 19:58:31,170] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:31,170] WARNING There is 1 run for ERX5777701\n",
      "[2025-04-16 19:58:31,171]    INFO Parsing run ERR6140859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'accession': 'ERR6140859',\n",
       "  'filename': 'ERR6140859_1.fastq.gz',\n",
       "  'filetype': 'fastq',\n",
       "  'filesize': 46548794,\n",
       "  'filenumber': 1,\n",
       "  'md5': '87fbe7c5b04a66a8f17da0f16bb6bf36',\n",
       "  'urltype': 'ftp',\n",
       "  'url': 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz'},\n",
       " {'accession': 'ERR6140859',\n",
       "  'filename': 'ERR6140859_2.fastq.gz',\n",
       "  'filetype': 'fastq',\n",
       "  'filesize': 48630523,\n",
       "  'filenumber': 2,\n",
       "  'md5': '49a6698e9c9099f21f6ace7953925027',\n",
       "  'urltype': 'ftp',\n",
       "  'url': 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ffq(parser.parse_args(['--ftp','ERX5777701']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cb3f9d-dda4-43b9-a09d-6a25e7fce3ff",
   "metadata": {},
   "source": [
    "##### Gives the same as the command line!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "174c0103-e01f-4680-9d3d-baa896260f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:32,187]    INFO Parsing Experiment ERX5777701\n",
      "[2025-04-16 19:58:32,356] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:32,488] WARNING There is 1 run for ERX5777701\n",
      "[2025-04-16 19:58:32,488]    INFO Parsing run ERR6140859\n",
      "[\n",
      "    {\n",
      "        \"accession\": \"ERR6140859\",\n",
      "        \"filename\": \"ERR6140859_1.fastq.gz\",\n",
      "        \"filetype\": \"fastq\",\n",
      "        \"filesize\": 46548794,\n",
      "        \"filenumber\": 1,\n",
      "        \"md5\": \"87fbe7c5b04a66a8f17da0f16bb6bf36\",\n",
      "        \"urltype\": \"ftp\",\n",
      "        \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz\"\n",
      "    },\n",
      "    {\n",
      "        \"accession\": \"ERR6140859\",\n",
      "        \"filename\": \"ERR6140859_2.fastq.gz\",\n",
      "        \"filetype\": \"fastq\",\n",
      "        \"filesize\": 48630523,\n",
      "        \"filenumber\": 2,\n",
      "        \"md5\": \"49a6698e9c9099f21f6ace7953925027\",\n",
      "        \"urltype\": \"ftp\",\n",
      "        \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!ffq --ftp ERX5777701"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e31c4-dfba-4c48-8023-584a671bfbdd",
   "metadata": {},
   "source": [
    "I realized later that using it without specifying source can allow you to learn much more about available resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ff38e2e-2114-4258-bc25-5af23d2499c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:58:33,647]    INFO Parsing Experiment ERX5777701\n",
      "[2025-04-16 19:58:33,658] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:58:33,659] WARNING There is 1 run for ERX5777701\n",
      "[2025-04-16 19:58:33,660]    INFO Parsing run ERR6140859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ERX5777701': {'accession': 'ERX5777701',\n",
       "  'title': 'Fly Cell Atlas: single-cell transcriptomes of the entire adult Drosophila - Smartseq2 dataset',\n",
       "  'platform': 'ILLUMINA',\n",
       "  'instrument': 'Illumina NovaSeq 6000',\n",
       "  'runs': {'ERR6140859': {'accession': 'ERR6140859',\n",
       "    'experiment': 'ERX5777701',\n",
       "    'study': 'ERP130174',\n",
       "    'sample': 'ERS7029664',\n",
       "    'title': 'Illumina NovaSeq 6000 paired end sequencing; Fly Cell Atlas: single-cell transcriptomes of the entire adult Drosophila - Smartseq2 dataset',\n",
       "    'attributes': {'ENA-FIRST-PUBLIC': '2021-07-02',\n",
       "     'ENA-LAST-UPDATE': '2021-07-02'},\n",
       "    'files': {'ftp': [{'accession': 'ERR6140859',\n",
       "       'filename': 'ERR6140859_1.fastq.gz',\n",
       "       'filetype': 'fastq',\n",
       "       'filesize': 46548794,\n",
       "       'filenumber': 1,\n",
       "       'md5': '87fbe7c5b04a66a8f17da0f16bb6bf36',\n",
       "       'urltype': 'ftp',\n",
       "       'url': 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz'},\n",
       "      {'accession': 'ERR6140859',\n",
       "       'filename': 'ERR6140859_2.fastq.gz',\n",
       "       'filetype': 'fastq',\n",
       "       'filesize': 48630523,\n",
       "       'filenumber': 2,\n",
       "       'md5': '49a6698e9c9099f21f6ace7953925027',\n",
       "       'urltype': 'ftp',\n",
       "       'url': 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz'}],\n",
       "     'aws': [],\n",
       "     'gcp': [],\n",
       "     'ncbi': []}}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ffq(parser.parse_args(['ERX5777701']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dff38a9-1fbe-4ea1-ac93-3ade4c17eb12",
   "metadata": {},
   "source": [
    "### Can I parse the Python result like documentation suggests to obtain the links from the ffq resultes to download raw data\n",
    "\n",
    "Under [the section 'Downloading data'](https://github.com/pachterlab/ffq/tree/898f56b0b9a07f152d2771fbb5157bf928febf4f#downloading-data):\n",
    "\n",
    ">\"ffq is specifically designed to download metadata and to facilitate obtaining links to sequence files. To download raw data from the links obtained with ffq you can use...\" curl among other things\n",
    "\n",
    "In [the documentation they say](https://github.com/pachterlab/ffq/tree/898f56b0b9a07f152d2771fbb5157bf928febf4f#ftp), \"Alternatively, the urls can be extracted from the json output with jq and then piped into cURL.\"   \n",
    "\n",
    "This is the command line equivalent example they provide in the documentation:\n",
    "\n",
    "```shell\n",
    "ffq --ftp SRR10668798 | jq -r '.[] | .url' | xargs curl -O\n",
    "```\n",
    "\n",
    "However, as ffq isn't registering as a command line command executable on the command line in OSG's access point (and I assume for execution point), is there a way I can I accomplish the equivalent with Python to set up for getting the sequence files?\n",
    "\n",
    "[Here](https://stackoverflow.com/a/65078827/8508004) suggests pyjq will work for the `jq` step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10c76e7e-2575-4f55-b5cf-4070d4ddd549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyjq -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32f1a2c3-f049-4160-b495-c36cf0ec2bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-16 19:59:16,945]    INFO Parsing Experiment ERX5777701\n",
      "[2025-04-16 19:59:16,955] WARNING Failed to parse experiment information from ENA XML. Falling back to ENA search...\n",
      "[2025-04-16 19:59:16,956] WARNING There is 1 run for ERX5777701\n",
      "[2025-04-16 19:59:16,957]    INFO Parsing run ERR6140859\n"
     ]
    }
   ],
   "source": [
    "raw_json_output = run_ffq(parser.parse_args(['--ftp','ERX5777701']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d70b0a70-939c-4fc5-9fed-045f283aaae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accession': 'ERR6140859',\n",
       "  'filename': 'ERR6140859_1.fastq.gz',\n",
       "  'filetype': 'fastq',\n",
       "  'filesize': 46548794,\n",
       "  'filenumber': 1,\n",
       "  'md5': '87fbe7c5b04a66a8f17da0f16bb6bf36',\n",
       "  'urltype': 'ftp',\n",
       "  'url': 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz'},\n",
       " {'accession': 'ERR6140859',\n",
       "  'filename': 'ERR6140859_2.fastq.gz',\n",
       "  'filetype': 'fastq',\n",
       "  'filesize': 48630523,\n",
       "  'filenumber': 2,\n",
       "  'md5': '49a6698e9c9099f21f6ace7953925027',\n",
       "  'urltype': 'ftp',\n",
       "  'url': 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_json_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b993ea-64d4-48ca-9a65-e7ec9d490df7",
   "metadata": {},
   "source": [
    "Parsing that based on example from [here](https://stackoverflow.com/a/65078827/8508004) and the ffq documentation. The example from stackoverflow:\n",
    "\n",
    "```python\n",
    "import pyjq\n",
    "print(pyjq.all( \".members[] | [.name]\", {\"members\": [ {\"name\": \"foo\"} ]} ))\n",
    "```\n",
    "\n",
    "Example from ffq documentation with jq:\n",
    "\n",
    "```shell\n",
    "$ ffq --ftp SRR10668798 | jq -r '.[] | .url' | xargs curl -O\n",
    "```\n",
    "\n",
    "So makes me think, this would work:\n",
    "\n",
    "```python\n",
    "import pyjq\n",
    "print(pyjq.all( \".[] | .url\",raw_json_output ))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "480a409d-1de2-472b-9556-574b92c77fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz', 'ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz']\n"
     ]
    }
   ],
   "source": [
    "import pyjq\n",
    "print(pyjq.all( \".[] | .url\",raw_json_output ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae68abd-dc71-4c8f-817c-5886113be84b",
   "metadata": {},
   "source": [
    "That worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2df99d2-650a-4230-ab77-f642c9826515",
   "metadata": {},
   "source": [
    "So to make the curl commands to get each set of specified fastq files, it would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "190ad8e3-6ef0-4e66-962a-55b862baa1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -OL ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz\n",
      "curl -OL ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "list_urls = pyjq.all( \".[] | .url\",raw_json_output ) \n",
    "for url in list_urls:\n",
    "    os.system(f\"echo curl -OL {url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b5629c-1650-49b3-9181-be213d630f41",
   "metadata": {},
   "source": [
    "Note that the above cell would time out for the `os.system(f\"curl -OL {url}\")` when run on MyBinder because FTP blocked there. (SO FOR NOW JUST ECHOING THE DRAFTED COMMANDS.) Oddly though it did work back in June 2023 (I had the old version showing curl retreiving the fastq files) when I ran it bt maybe Gesis hadn't blocked FTP port at that time. (I know that I didn't run in Huggigface because installing `pyjq` fails there.)  \n",
    "Where I'm intending to run this, `curl` works on the command line and FTP port is open, and so I think this is fine approach for that step. I wouldn't have been able to use `os.system(f\"ffq -ftp {acc_id}\")` there on OSG OSpool because that was the issue that ffq wasn't getting registered to the command line on OSG OSPool Singularity Apptainer.    \n",
    "At first glance, this maybe doesn't jibe fully with the 'pure-Python way' of using `ffq` that I was suggesting at the top of this document; however, the curl retrieval is a downstream step [and could be done with Python using the requests module](https://stackoverflow.com/questions/46311212/pythons-requests-equivalent-of-curl-o)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91ee49-8eb5-49ea-b495-d1ee0fc42edd",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "### ffq-api's public instance used in conjunction with `curl` isn't a replacement for using ffq\n",
    "\n",
    "OH WAIT, **this now works on MyBinder!!!** The rest of this section was originally drafted when the code below didn't work in the session, and so take the rest of this section with a grain of salt for now (leaving it for now because it may go back to not working as MyBinder changes)....\n",
    "\n",
    "`curl` works to retrieve via FTP link in the place I want to use `ffq` (OSG's OSPool) but cannot seem to get ffq to register as command line there in the Singularity appatainer. So in theory I can use curl with ffq-api's public instance to use `ffq` even where it isn't available on command line. However,currently it doesn't get anything for `ERX5777701`, despite the direct current `ffq working well with `ERX5777701` above.\n",
    "\n",
    "Showing it doesn't really work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e14e17b1-246b-4fe8-b1f3-93274684010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"results\": {\n",
      "    \"ERX5777701\": {\n",
      "      \"accession\": \"ERX5777701\",\n",
      "      \"title\": \"Fly Cell Atlas: single-cell transcriptomes of the entire adult Drosophila - Smartseq2 dataset\",\n",
      "      \"platform\": \"ILLUMINA\",\n",
      "      \"instrument\": \"Illumina NovaSeq 6000\",\n",
      "      \"runs\": {\n",
      "        \"ERR6140859\": {\n",
      "          \"accession\": \"ERR6140859\",\n",
      "          \"experiment\": \"ERX5777701\",\n",
      "          \"study\": \"ERP130174\",\n",
      "          \"sample\": \"ERS7029664\",\n",
      "          \"title\": \"Illumina NovaSeq 6000 paired end sequencing; Fly Cell Atlas: single-cell transcriptomes of the entire adult Drosophila - Smartseq2 dataset\",\n",
      "          \"attributes\": {\n",
      "            \"ENA-FIRST-PUBLIC\": \"2021-07-02\",\n",
      "            \"ENA-LAST-UPDATE\": \"2021-07-02\"\n",
      "          },\n",
      "          \"files\": {\n",
      "            \"ftp\": [\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"ERR6140859_1.fastq.gz\",\n",
      "                \"filetype\": \"fastq\",\n",
      "                \"filesize\": 46548794,\n",
      "                \"filenumber\": 1,\n",
      "                \"md5\": \"87fbe7c5b04a66a8f17da0f16bb6bf36\",\n",
      "                \"urltype\": \"ftp\",\n",
      "                \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_1.fastq.gz\"\n",
      "              },\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"ERR6140859_2.fastq.gz\",\n",
      "                \"filetype\": \"fastq\",\n",
      "                \"filesize\": 48630523,\n",
      "                \"filenumber\": 2,\n",
      "                \"md5\": \"49a6698e9c9099f21f6ace7953925027\",\n",
      "                \"urltype\": \"ftp\",\n",
      "                \"url\": \"ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR614/009/ERR6140859/ERR6140859_2.fastq.gz\"\n",
      "              }\n",
      "            ],\n",
      "            \"aws\": [\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"FCA_P43_male_oenocyte_A10_L004_R1.fastq.gz.1\",\n",
      "                \"filetype\": \"fastq\",\n",
      "                \"filesize\": null,\n",
      "                \"filenumber\": 1,\n",
      "                \"md5\": null,\n",
      "                \"urltype\": \"aws\",\n",
      "                \"url\": \"s3://sra-pub-src-18/ERR6140859/FCA_P43_male_oenocyte_A10_L004_R1.fastq.gz.1\"\n",
      "              },\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"FCA_P43_male_oenocyte_A10_L004_R2.fastq.gz.1\",\n",
      "                \"filetype\": \"fastq\",\n",
      "                \"filesize\": null,\n",
      "                \"filenumber\": 2,\n",
      "                \"md5\": null,\n",
      "                \"urltype\": \"aws\",\n",
      "                \"url\": \"s3://sra-pub-src-18/ERR6140859/FCA_P43_male_oenocyte_A10_L004_R2.fastq.gz.1\"\n",
      "              },\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"ERR6140859\",\n",
      "                \"filetype\": \"sra\",\n",
      "                \"filesize\": null,\n",
      "                \"filenumber\": 1,\n",
      "                \"md5\": null,\n",
      "                \"urltype\": \"aws\",\n",
      "                \"url\": \"https://sra-pub-run-odp.s3.amazonaws.com/sra/ERR6140859/ERR6140859\"\n",
      "              },\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"ERR6140859.lite.1\",\n",
      "                \"filetype\": \"sra\",\n",
      "                \"filesize\": null,\n",
      "                \"filenumber\": 1,\n",
      "                \"md5\": null,\n",
      "                \"urltype\": \"aws\",\n",
      "                \"url\": \"s3://sra-pub-zq-3/ERR6140859/ERR6140859.lite.1\"\n",
      "              }\n",
      "            ],\n",
      "            \"gcp\": [\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"ERR6140859.lite.1\",\n",
      "                \"filetype\": \"sra\",\n",
      "                \"filesize\": null,\n",
      "                \"filenumber\": 1,\n",
      "                \"md5\": null,\n",
      "                \"urltype\": \"gcp\",\n",
      "                \"url\": \"gs://sra-pub-zq-106/ERR6140859/ERR6140859.lite.1\"\n",
      "              }\n",
      "            ],\n",
      "            \"ncbi\": [\n",
      "              {\n",
      "                \"accession\": \"ERR6140859\",\n",
      "                \"filename\": \"ERR6140859.lite.1\",\n",
      "                \"filetype\": \"sra\",\n",
      "                \"filesize\": null,\n",
      "                \"filenumber\": 1,\n",
      "                \"md5\": null,\n",
      "                \"urltype\": \"ncbi\",\n",
      "                \"url\": \"https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos1/sra-pub-zq-38/ERR006/6140/ERR6140859/ERR6140859.lite.1\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"meta\": {\n",
      "    \"ffq_api_version\": \"0.3.3\",\n",
      "    \"ffq_version\": \"0.3.1\",\n",
      "    \"query\": {\n",
      "      \"IDs\": \"ERX5777701\",\n",
      "      \"search_type\": null,\n",
      "      \"level\": null,\n",
      "      \"links\": null\n",
      "    },\n",
      "    \"request\": {\n",
      "      \"start\": \"2025-04-16T19:59:12.750338\",\n",
      "      \"finish\": \"2025-04-16T19:59:13.290274\",\n",
      "      \"duration_seconds\": 0.539936\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "output = !curl https://ffq.seqera.io/v1alpha1/ERX5777701 \n",
    "import json\n",
    "# pretty print json based on https://www.digitalocean.com/community/tutorials/python-pretty-print-json & https://stackoverflow.com/a/36941257/8508004\n",
    "json_object2 = json.loads(output[-1])\n",
    "json_formatted_str = json.dumps(json_object2, indent=2)\n",
    "print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c2b72-f95d-420a-aa8b-d3f46076b72f",
   "metadata": {},
   "source": [
    "Note, that none of the useful URLs or **anything** retrieved!\n",
    "\n",
    "Yet, the example in the `ffq-api` documentation (`curl https://ffq.seqera.io/v1alpha1/SRR9990627 | jq`) works and so I don't know why I get different results than actually using current ffq.\n",
    "\n",
    "-----\n",
    "\n",
    "(Note to self I ended up using `sratoolkit` to fetch the fastqs when I wanted to save space/time on the remote machine.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
